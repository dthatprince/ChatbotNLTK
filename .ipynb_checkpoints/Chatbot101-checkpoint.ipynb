{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs                  #beautifulsoup4 library for parsing the webpage\n",
    "import urllib.request             #the urllib library for connection to a remote webpage\n",
    "import re                         #the re  library for performing regex operation\n",
    "\n",
    "import nltk              #the nltk  library for natural language processing\n",
    "import numpy as np       #the numpy  library for basic array operations\n",
    "import random            #the random  library is used for random number generation.\n",
    "import string            #the string  library is used for string manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping the article from the wiki page\n",
    "\n",
    "rawdata = urllib.request.urlopen('https://en.wikipedia.org/wiki/Global_warming')  \n",
    "rawdata = rawdata.read()\n",
    " \n",
    "html_data = bs.BeautifulSoup(rawdata,'html.parser')\n",
    " \n",
    "all_paragraphs =html_data.find_all('p')\n",
    " \n",
    "article_content = \"\"\n",
    " \n",
    "for p in all_paragraphs:  \n",
    "    article_content += p.text\n",
    "    \n",
    "article_content =  article_content.lower() #turning all words to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing numbers from our dataset and replace multiple empty spaces with single space.\n",
    "#(This step is optional, you can skip it)\n",
    "\n",
    "article_content = re.sub(r'\\[[0-9]*\\]', ' ', article_content ) \n",
    "article_content = re.sub(r'\\s+', ' ', article_content )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing the article into sentences:\n",
    "\n",
    "sentence_list = nltk.sent_tokenize(article_content)\n",
    "article_words= nltk.word_tokenize(article_content )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization and Punctuation Removal\n",
    "\n",
    "Lemmatization refers to reducing the word to its root form, as available in the dictionary. For instance, the lemmatized version of the word eating will be eat , better will be good , medium will be media and so on.\n",
    "\n",
    "Lemmatization helps find similarity between the words since similar words can be used in different tense and different degrees. Lemmatizing them makes them uniform.\n",
    "\n",
    "Similarly, we will remove punctuations from our text because punctuations do not convey any meaning and if we do not remove them, they will also be treated as tokens.\n",
    "\n",
    "We will use NLTKâ€™s punkt  and wordnet modules for punctuation removal.\n",
    "We can then use the WordNetLemmatizer object from the nltk.stem  module for lemmatizing the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    " \n",
    "def LemmatizeWords(words):\n",
    "    return [lemmatizer.lemmatize(word) for word in words]\n",
    " \n",
    "remove_punctuation= dict((ord(punctuation), None) for punctuation in string.punctuation)\n",
    " \n",
    "def RemovePunctuations(text):\n",
    "    return LemmatizeWords(nltk.word_tokenize(text.lower().translate(remove_punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Greetings\n",
    "\n",
    "greeting_input_texts = (\"hey\", \"hi\", \"hello\", \"morning\", \"evening\",\"greetings\",\"afternoon\",)\n",
    "greeting_replie_texts = [\"hey\", \"hey, how are you?\", \"ðŸ‘‹ how may i help you?\", \"hello there\", \"hello\", \"Welcome, how are you\"]\n",
    "\n",
    "def reply_greeting(text):\n",
    " \n",
    "    for word in text.split():\n",
    "        if word.lower() in greeting_input_texts:\n",
    "            return random.choice(greeting_replie_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Response:\n",
    "Refer to ReadMe file Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_reply(user_input):\n",
    "    chatbot_response=''\n",
    "    sentence_list.append(user_input)\n",
    "    word_vectors = TfidfVectorizer(tokenizer=RemovePunctuations, stop_words='english')\n",
    "    vecrorized_words = word_vectors.fit_transform(sentence_list)\n",
    "    similarity_values = cosine_similarity(vecrorized_words[-1], vecrorized_words)\n",
    "    similar_sentence_number =similarity_values.argsort()[0][-2]\n",
    "    similar_vectors = similarity_values.flatten()\n",
    "    similar_vectors.sort()\n",
    "    matched_vector = similar_vectors[-2]\n",
    "    if(matched_vector ==0):\n",
    "        chatbot_response=chatbot_response+\"I am sorry! I don't understand you. ask me something else\"\n",
    "        return chatbot_response\n",
    "    else:\n",
    "        chatbot_response = chatbot_response +sentence_list[similar_sentence_number]\n",
    "        return chatbot_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interacting with User\n",
    "\n",
    "we will set a flag \"continue_discussion\" to True.\n",
    "Next,  execute a while loop inside which we ask the user to input his/her questions regarding global warming.\n",
    "The loop executes until the  \"continue_discussion\"  flag is set to True.\n",
    "If the user input is equal to the string â€˜byeâ€™, the loop terminates by setting  \"continue_discussion\"  flag to False .\n",
    "Else if the user input contains words like thank â€˜thanksâ€™, â€˜thank you very muchâ€™ or â€˜thank youâ€™ the response generated will be â€˜Chatbot: Most welcomeâ€™.\n",
    "If the user input contains a greeting, the response generated will contain greeting. \n",
    "Finally, if the user input doesnâ€™t contain â€˜byeâ€™ or â€˜thank youâ€™ words or greetings, the user input is sent to give_reply function that we created in the last section, the function returns an appropriate response based on cosine similarity.\n",
    "\n",
    "If you run the above script, you should see a text box asking you for any question regarding global warming, based on the question, a response will be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is Prince, I will answer your questions about global warming: say bye to end conversation.\n"
     ]
    }
   ],
   "source": [
    "continue_discussion=True\n",
    "print(\"Hello, my name is Prince, I will answer your questions about global warming: say bye to end conversation.\")\n",
    "while(continue_discussion==True):\n",
    "    user_input = input()\n",
    "    user_input = user_input .lower()\n",
    "    if(user_input !='bye'):\n",
    "        if(user_input =='thanks' or user_input =='thank you very much'  or user_input =='thank you'):\n",
    "            continue_discussion=False\n",
    "            print(\"Prince: Most welcome\")\n",
    "        else:\n",
    "            if(reply_greeting(user_input)!=None):\n",
    "                print(\"Chatbot: \"+reply_greeting(user_input))\n",
    "            else:\n",
    "                print(\"Prince: \",end=\"\")\n",
    "                print(give_reply(user_input))\n",
    "                sentence_list.remove(user_input)\n",
    "    else:\n",
    "        continue_discussion=False\n",
    "        print(\"Prince: Take care, bye ..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
